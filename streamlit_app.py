import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.schema import (
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    SystemMessage, 
    # äººé–“ã®è³ªå•
    HumanMessage, 
    # ChatGPTã®è¿”ç­”
    AIMessage)
from langchain.callbacks import get_openai_callback
from langchain.callbacks import StreamlitCallbackHandler


# ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨ã™ã‚‹
from dotenv import load_dotenv
import os

def init_page():
    # .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    load_dotenv()

    ## streamlitã®è¨­å®š 
    st.set_page_config(
        page_title="My Great ChatGPT",
        page_icon="ğŸ¤—"
    )
    st.header("My Great ChatGPT ğŸ¤—")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¡¨ç¤º
    st.sidebar.title("Options")
    

def select_model():
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³ã‚’è¨­ç½®
    model = st.sidebar.radio("Choose a model:",("GPT-3.5", "GPT-4"))
    if model == "GPT-3.5":
        model_name = "gpt-3.5-turbo"
    else:
        model_name = "gpt-4"
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’è¿½åŠ ã—ã€temperatureã‚’0ã‹ã‚‰2ã¾ã§ã®ç¯„å›²ã§é¸æŠå¯èƒ½ã«ã™ã‚‹
    # åˆæœŸå€¤ã¯0.0ã€åˆ»ã¿å¹…ã¯0.1ã¨ã™ã‚‹
    temperature = st.sidebar.slider("Temperature:", min_value=0.0, max_value=2.0, value=0.0,step=0.01)
        
    # ChatGPT APIã‚’å‘¼ã‚“ã§ãã‚Œã‚‹æ©Ÿèƒ½
    return ChatOpenAI(temperature=temperature, openai_api_key=os.environ.get("OPENAI_API_KEY"), model_name=model_name)

def init_messages():
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒœã‚¿ãƒ³ã‚’è¨­ç½®
    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    if clear_button or "message" not in st.session_state:
        st.session_state.messages = [
            SystemMessage(content="You are a helpful assistant.")
        ]
        st.session_state.cost = []
        st.session_state.token = []

def get_answer(llm, messages):
    with get_openai_callback() as cb:
        answer = llm(messages) 
    return answer.content, cb.total_cost, cb.total_tokens

def main():
    init_page()
    llm = select_model()
    init_messages()

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = [
            SystemMessage(content="You are a helpful assistant.")
        ]

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("ChatGPT is typing ..."):
            answer, cost, token = get_answer(llm,st.session_state.messages)
        st.session_state.cost.append(cost)
        st.session_state.token.append(token)
        st.session_state.messages.append(AIMessage(content=answer))
        
    # # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get('messages', [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message('assistant'):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message('user'):
                st.markdown(message.content)
        else:  # isinstance(message, SystemMessage):
            st.write(f"System message: {message.content}")

    # ã‚³ã‚¹ãƒˆè¡¨ç¤º
    costs = st.session_state.get('cost', [])
    st.sidebar.markdown("## costs")
    st.sidebar.markdown(f"### totalcosts: ${sum(costs):.5f}")
    for cost in costs:
        st.sidebar.markdown(f"- ${cost:.5f}")

    # ãƒˆãƒ¼ã‚¯ãƒ³è¡¨ç¤º
    tokens = st.session_state.get('token', [])
    st.sidebar.markdown("## tokens")
    st.sidebar.markdown(f"### totaltokens: {sum(tokens):.5f}")
    for token in tokens:
        st.sidebar.markdown(f"- {token:.5f}")

if __name__ == '__main__':
    main()